eu ai act is in force and phasing in over 2025-2027
if already following uk ico ai and data protection risk toolkit partway there
most act obligations map to existing uk gdpr risk controls
piece gives dates that matter and practical mapping so product teams can ship compliant features without boiling ocean

The dates that actually matter EU AI Act

The Act entered into force on 1 Aug 2024. The key application dates for product teams: 2 Feb 2025, prohibitions and AI literacy, 2 Aug 2025, governance plus GPAI, 2 Aug 2026, most remaining obligations, and 2 Aug 2027, some high-risk systems embedded in regulated products.

Milestones

- 2 Feb 2025 - Prohibited uses and AI literacy begin applying, untargeted scraping of facial images for recognition is banned
- 10 Jul 2025 - GPAI Code of Practice published by the Commission to help providers demonstrate compliance. Participation is voluntary but influential
- 2 Aug 2025 - Governance plus GPAI obligations apply, documentation, transparency, copyright summaries, model evaluation for systemic-risk models
- 2 Aug 2026 - Full application for most systems, risk management, data tech docs, monitoring, incident reporting
- 2 Aug 2027 - Some high-risk, product-embedded systems gain an extended transition period

The UK anchor the ICO AI and Data Protection Risk Toolkit

The ICO toolkit is a practical set of questions, controls, templates aligned to UK GDPR. It is currently under review, post-19 Jun 2025 Data Use and Access Act, but the control themes remain stable and useful for EU AI Act prep.

What the ICO toolkit covers at a glance

- Governance and accountability, roles, sign-offs, audit trails
- Data protection impact assessments DPIA, lawful basis, necessity tests
- Training data controls, quality, bias, security, and model monitoring
- Transparency to users, human oversight, redress routes

Map ICO toolkit to EU AI Act obligations

Use the ICO toolkit as the working checklist. Add the AI Act-specific outputs noted below.

Governance and risk management

- ICO: assign owners, record decisions, keep an audit trail
- AI Act add-ons: maintain a risk-management system per AI Act with documented hazard identification, evaluation, mitigation. Add AI literacy measures for staff by Feb 2025

DPIA and technical documentation

- ICO: DPIA for high-risk processing, link to assets and vendors
- AI Act add-ons: keep technical documentation and logs sufficient for market surveillance authorities. Ensure traceability of datasets and evaluation results by Aug 2026

Dataset quality, bias, and data governance

- ICO: document sources, lawful basis, minimisation, quality checks
- AI Act add-ons: for high-risk systems, implement data governance and management practices, relevance, representativeness, error handling, and post-market monitoring obligations

Human oversight and transparency

- ICO: define oversight points and user notices
- AI Act add-ons: implement usable human-in-the-loop controls and end-user AI interaction disclosures where required. Align to the prohibition list from Feb 2025

GPAI foundation models specifics

- ICO: general risk controls still apply
- AI Act add-ons: if providing a GPAI model, meet GPAI transparency, documentation, copyright data-summary. For systemic-risk models, perform model evaluation, adversarial testing, cybersecurity, serious-incident reporting starting Aug 2025. Legacy models placed pre-Aug 2025 may have until Aug 2027. Consider aligning with the GPAI Code of Practice Jul 2025

Ship list concrete outputs product teams should produce

Core documents

- AI System Register, purpose, users, data, risks, owners, deployment status
- Risk-Management File, hazards, mitigations, residual risk, sign-offs
- Technical Documentation, architecture, data lineage, metrics, evals, logs
- DPIA plus UK EU privacy notices keyed to specific features

Operational controls

- Human oversight SOPs, when to intervene, rollback, escalate
- Post-market monitoring plan, alerts, incident criteria, reporting channel
- Evaluation harness, accuracy, bias, robustness, drift, release gates

For GPAI providers or heavy users

- Training-data summary for copyright transparency
- Security and testing plan for systemic-risk models, red-team adversarial tests
- Participation decision on the GPAI Code of Practice, document rationale

90-day backlog sequenced

Days 0-15

- Inventory AI use cases, classify risk, identify any prohibited candidates, assign product owners

Days 16-45

- Complete DPIAs, draft system registers, define human oversight and rollback SOPs

Days 46-75

- Stand up evaluation and logging, start post-market monitoring, capture AI literacy activities

Days 76-90

- Finalise technical docs, run a release-gate dry-run, prepare incident templates

Common traps to avoid

Treating UK and EU as separate builds

- Often meet both by using the ICO toolkit as the operational backbone and layering AI Act-specific documentation and timing on top

Ignoring GPAI dependencies

- Even if not providing a GPAI model, vendors do. Track their Aug 2025 posture and Code-of-Practice participation

Waiting for standards to finish

- Most obligations apply before all standards are final. Ship the docs and controls now, retrofit to future standards where needed
